{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUYnJVTUlZU0",
        "outputId": "07bc6418-d683-451d-99ef-cf26fc09a3e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Mapping: {'te': 0, 'kn': 1, 'ml': 2, 'ta': 3, 'hi': 4, 'mr': 5, 'gu': 6, 'bn': 7, 'pa': 8, 'ur': 9, 'or': 10, 'sd': 11}\n",
            "Training set size: 4200\n",
            "Test set size: 1800\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/Big_Dataset.csv')\n",
        "\n",
        "# Fix column name if necessary (to ensure consistency)\n",
        "if 'Langid' in data.columns:\n",
        "    data.rename(columns={'Langid': 'Langid'}, inplace=True)\n",
        "\n",
        "# Define features and labels\n",
        "X = data['Sentences'].dropna()  # Sentences/Texts\n",
        "y = data['Langid'].dropna()  # Language labels (ensure correct column name)\n",
        "\n",
        "# Split into train and validation sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Create a mapping of unique language codes to integer labels\n",
        "label_map = {label: idx for idx, label in enumerate(y.unique())}\n",
        "\n",
        "# Convert labels to numerical format\n",
        "y_train_encoded = y_train.map(label_map)\n",
        "y_test_encoded = y_test.map(label_map)\n",
        "\n",
        "# Load the pretrained multilingual BERT model\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-multilingual-cased\", num_labels=len(label_map)\n",
        ")\n",
        "\n",
        "# Print label mapping for reference\n",
        "print(\"Label Mapping:\", label_map)\n",
        "\n",
        "# Check the size of the training and test datasets\n",
        "print(f\"Training set size: {X_train.shape[0]}\")\n",
        "print(f\"Test set size: {X_test.shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QbdSl9gilh6g"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, AdamW\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "iw23D3KAl3QO"
      },
      "outputs": [],
      "source": [
        "# 1. Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mZ8CIyqTl6g8"
      },
      "outputs": [],
      "source": [
        "# Tokenize the sentences (both train and test sets)\n",
        "train_encodings = tokenizer(list(X_train), padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "test_encodings = tokenizer(list(X_test), padding=True, truncation=True, max_length=128, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "arzVu2XQmCdK"
      },
      "outputs": [],
      "source": [
        "# 2. Prepare DataLoader\n",
        "# Convert the labels into tensors\n",
        "train_labels = torch.tensor(y_train_encoded.values)\n",
        "test_labels = torch.tensor(y_test_encoded.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XvjGo3xtmIEv"
      },
      "outputs": [],
      "source": [
        "# Create TensorDataset for both training and test datasets\n",
        "train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], train_labels)\n",
        "test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "DoLa4GrURT9z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Hf4y_1XcmM3G"
      },
      "outputs": [],
      "source": [
        "# Create DataLoaders for batching\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_OTD0QbmRUB",
        "outputId": "61026235-9eae-4c3a-9646-3779c017bfd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 3. Set up the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlbAGmnxmUBu",
        "outputId": "1050fb8c-78ba-4ef9-bd63-47112a3f3102"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=12, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# 4. Training loop\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "3nvCwYzJmXS4"
      },
      "outputs": [],
      "source": [
        "epochs = 30\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "5Y2z0IH2mgRF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe4232bd-e976-43ec-c4f4-6f3f515300c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/30: 100%|██████████| 132/132 [01:27<00:00,  1.52batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 - Training loss: 1.7043093284874251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30 - Training loss: 0.5891606523232027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/30 - Training loss: 0.29541441566790594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/30 - Training loss: 0.14587096638525976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/30 - Training loss: 0.08352493717702049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/30 - Training loss: 0.05724335122486633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/30 - Training loss: 0.0354004738513719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30 - Training loss: 0.02395020620403529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30 - Training loss: 0.01393175316325417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30 - Training loss: 0.0233291472223672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30 - Training loss: 0.020818091960708527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/30 - Training loss: 0.04281103343942739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/30 - Training loss: 0.023400667966625682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/30 - Training loss: 0.018407123706613977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/30 - Training loss: 0.041174949132696245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/30 - Training loss: 0.01970097564238434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/30 - Training loss: 0.00407971565216554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/30 - Training loss: 0.006021793819716991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/30 - Training loss: 0.013299077020774625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/30 - Training loss: 0.019434632384218276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/30 - Training loss: 0.028604894033350953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/30 - Training loss: 0.016259735455440186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/30 - Training loss: 0.01760870157423514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/30 - Training loss: 0.002726288998294904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/30 - Training loss: 0.0016001095072803737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/30 - Training loss: 0.0013961246965636471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/30 - Training loss: 0.001547411817944411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/30 - Training loss: 0.001085918612344275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/30 - Training loss: 0.0010135490059231718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/30: 100%|██████████| 132/132 [01:26<00:00,  1.53batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/30 - Training loss: 0.001576722610590161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm  # Import tqdm for progress bar\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Wrap the train_loader with tqdm for a progress bar\n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\", unit=\"batch\"):\n",
        "        # Get the inputs and labels\n",
        "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = outputs.loss\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Backward pass (compute gradients)\n",
        "        loss.backward()\n",
        "\n",
        "        # Update model parameters\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} - Training loss: {avg_train_loss}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "AmcYhVBvm1ZU"
      },
      "outputs": [],
      "source": [
        "# 5. Save the model\n",
        "model.save_pretrained(\"./language_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "4FLNSGzpES1D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3c74349-2f3a-4ad6-da2b-a873f4862bf4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./language_model/tokenizer_config.json',\n",
              " './language_model/special_tokens_map.json',\n",
              " './language_model/vocab.txt',\n",
              " './language_model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "tokenizer.save_pretrained(\"./language_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "QueJ8zY31yN7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86439fff-9b3b-4784-ab82-89a2c13e2920"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to predicted_language_codes.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# Load the trained model and tokenizer\n",
        "model_path = \"./language_model\"  # Path where the model is saved\n",
        "model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "# Move model to device (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "# Function to predict language code\n",
        "def predict_language(sentence):\n",
        "    # Tokenize the input sentence\n",
        "    encoding = tokenizer(sentence, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "    # Move input tensors to the correct device\n",
        "    input_ids = encoding[\"input_ids\"].to(device)\n",
        "    attention_mask = encoding[\"attention_mask\"].to(device)\n",
        "\n",
        "    # Make prediction\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    # Get predicted label\n",
        "    predicted_label_id = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    # Convert back to language code using label_map\n",
        "    predicted_language = [lang for lang, idx in label_map.items() if idx == predicted_label_id][0]\n",
        "\n",
        "    return predicted_language\n",
        "\n",
        "# Predict for all test sentences\n",
        "predicted_languages = [predict_language(sentence) for sentence in X_test]\n",
        "\n",
        "# Create a DataFrame with actual and predicted language codes\n",
        "output_df = pd.DataFrame({\n",
        "    'Sentence': X_test.values,             # Original sentence\n",
        "    'Actual Language Code': y_test.values,  # Original language label\n",
        "    'Predicted Language Code': predicted_languages  # Predicted language code\n",
        "})\n",
        "\n",
        "# Save to CSV file\n",
        "output_file = \"predicted_language_codes.csv\"\n",
        "output_df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Predictions saved to {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "P2aApBRd0UI4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78fc8925-b3fa-4d96-a1d9-2c39c7683292"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "VHr9ApGy01Dx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e5c817c-d946-410c-958d-8988b10b1f51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 91.56%\n"
          ]
        }
      ],
      "source": [
        "#Calculate accuracy score\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, predicted_languages)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Vf8JAsw5BCJ-"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "import torch\n",
        "\n",
        "# Path to the saved model and tokenizer\n",
        "model_pathe = '/content/language_model'\n",
        "tokenizer_pathe= '/content/language_model'\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model = BertForSequenceClassification.from_pretrained(model_pathe)\n",
        "tokenizer = BertTokenizer.from_pretrained(tokenizer_pathe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "sMTEPPwbojdi"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df1=pd.read_csv(\"/content/testing data.csv\")\n",
        "# languages = ['te', 'kn', 'ml', 'ta', 'hi', 'mr', 'gu', 'bn', 'pa', 'ur', 'or', 'sd']"
      ],
      "metadata": {
        "id": "lnMgI2ExsH2C"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "HuzSqbOc8RgB"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# # Create lists to store the predicted language codes and confidence scores\n",
        "# predicted_labels = []\n",
        "# confidence_scores = []\n",
        "\n",
        "# # Loop through each sentence and perform inference\n",
        "# for sentence in df1['Sentence']:\n",
        "#     # Tokenize the sentence\n",
        "#     inputs = tokenizer(sentence, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "\n",
        "#     # Perform inference (turn off gradients for inference)\n",
        "#     with torch.no_grad():\n",
        "#         outputs = model(**inputs)\n",
        "\n",
        "#     # Get the logits (raw predictions)\n",
        "#     logits = outputs.logits\n",
        "\n",
        "#     # Apply softmax to get the probabilities (confidence scores)\n",
        "#     probabilities = F.softmax(logits, dim=-1)\n",
        "\n",
        "#     # Get the predicted class (index of max probability)\n",
        "#     predicted_class = torch.argmax(logits, dim=-1)\n",
        "\n",
        "#     # Get the confidence score (probability of the predicted class)\n",
        "#     confidence_score = probabilities[0, predicted_class].item()\n",
        "\n",
        "#     # Map the predicted class index to the corresponding language code\n",
        "#     predicted_language = languages[predicted_class.item()]\n",
        "\n",
        "#     # Append the predictions and confidence score to the lists\n",
        "#     predicted_labels.append(predicted_language)\n",
        "#     confidence_scores.append(confidence_score)\n",
        "\n",
        "# # Add the predictions to the dataframe\n",
        "# df1['predicted_language_code'] = predicted_labels\n",
        "# df1['confidence_score'] = confidence_scores\n",
        "\n",
        "# # Display the updated dataframe\n",
        "# print(df1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "C8_kYvQI85AS"
      },
      "outputs": [],
      "source": [
        "# df1.to_csv('testing_results.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mbvxQyQsBCNY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "0462f7a4-3831-44b3-a5c6-c7059edd04bf"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tokenizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e599832e5df0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Tokenize the input text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ],
      "source": [
        "input_text= \"Jadon vi kujh anakiasiya vaparda hai, hara koi anukula hona di koshish karada hai, apaniya yojanava nu anukula banaunda hai, nave hunara sikhada hai, ate apani yatra jari rakhada hai, iha vishwasa karade hoye ki tabadali nave mauke lia sakadi hai.\"\n",
        "# Tokenize the input text\n",
        "\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "9y7LO3_1BCRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e85e74b-4ae8-4a5d-e502-20a585cb8cf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted language: pa\n",
            "Confidence score: 0.9996\n"
          ]
        }
      ],
      "source": [
        "# Perform inference (turn off gradients for inference)\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# Get the logits (raw predictions)\n",
        "logits = outputs.logits\n",
        "\n",
        "# Apply softmax to get the probabilities (confidence scores)\n",
        "probabilities = F.softmax(logits, dim=-1)\n",
        "\n",
        "# If it's a classification task, you can get the predicted class\n",
        "predicted_class = torch.argmax(logits, dim=-1)\n",
        "# Get the confidence score (the probability of the predicted class)\n",
        "confidence_score = probabilities[0, predicted_class].item()\n",
        "\n",
        "# Print the predicted class (assuming you have class labels corresponding to languages)\n",
        "# You will need to map the predicted class index to its corresponding language\n",
        "languages = ['te', 'kn', 'ml', 'ta', 'hi', 'mr', 'gu', 'bn', 'pa', 'ur', 'or', 'sd']  # Example language labels\n",
        "predicted_language = languages[predicted_class.item()]\n",
        "\n",
        "print(f\"Predicted language: {predicted_language}\")\n",
        "print(f\"Confidence score: {confidence_score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwnVUIXxBCb0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xu6lu6jHBCfR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}